=Introduction to ROC Reader Studies=

ROC reader studies are designed to evaluate and compare imaging devices and acquisition protocols, or generally 
evaluate image quality according to an objective task. The ROC task is a classification task, e.g., classifying 
a patient as non-diseased or diseased, an image as signal-absent or signal-present. Image quality is then 
defined as the ability of a reader (e.g., a radiologist) to perform such a task. 

In a typical ROC reader study the reader is presented with one of two mutually exclusive alternatives (e.g. a 
tumor-present image or a tumor-absent image). The observer is then asked to rate his or her confidence level of 
which alternative is presented (e.g., the confidence level of tumor presence on an image). Any number of 
responses may be used to rate the confidence level. For example, in some clinical reader studies, a set of five 
confidence level responses is used with 1 representing "absolutely sure there is no tumor"ù and 5 representing 
"absolutely sure there is tumor present". Alternatively, reader studies may ask the observer to use a continuous 
or quasi-continuousù rating scale; ratings may be a number from 0 to 1, or 1 to 100. The rating values are 
collected for both non-diseased and diseased cases. 

Given ratings for non-diseased and diseased cases, an ROC curve can be traced out by calculating the 
sensitivity/specificity (TPF/TNF) pair for each confidence level, or threshold, possible [1]. An ROC curve 
illustrates the tradeoff between sensitivity and specificity of the reader across all thresholds. This tradeoff 
is realized by a change in the reader's threshold. In the case of breast cancer screening via mammography, when 
the threshold is made more aggressive the reader recalls more women for additional imaging, increasing his or 
her sensitivity at the price of lower specificity.  If the reader's threshold is moved in the opposite 
direction, the reader will recall fewer women; the reader is less aggressive, decreasing his or her sensitivity 
with the concomitant result of increased specificity. The area under this ROC curve (AUC) is a summary 
figure-of-merit for describing how well a reader is able to separate the population of diseased patients from 
non-diseased patients.

One interpretation of AUC is that it is the reader's average sensitivity over all possible specificities. As 
such, it is a global summary of task performance that avoids thresholds entirely. AUC is also mathematically 
equivalent to the probability that a random reader will correctly choose the signal-present image over the 
signal-absent image when a pair is presented side-by-side or sequentially, as is done in a 2-alternative forced 
choice (2AFC) task. 

To account for the variability in readers, an ROC study is often conducted in a multi-reader paradigm. The 
endpoint of such an ROC reader study is the reader-averaged AUC value.  The uncertainty in the reader-averaged 
AUC suffers from two sources of variability: the readers and the cases. To account for both sources of 
variability, reader studies often involve several trained readers in addition to a dataset of diseased and 
non-diseased cases. One popular study design for estimating AUC is the fully crossed study design in which every 
reader reads every case. Statistical methods have been proposed in the literature to analyze fully-crossed MRMC 
data [1-9]. The origin of each method differs, and consequently, the estimation process of each method differs. 
Additionally, each method has at its foundation a different decomposition, or representation, of the total 
variance.
